# Feedback Integration + Learning Loop (Phase 3)

## Overview

This closes the loop on the three-tier discovery engine. Completion interviews now feed richer context ‚Üí reading analytics inform Prospero's conversation ‚Üí premise selection behavior adjusts discovery_tolerance over time ‚Üí future premises get smarter.

**Key Concept:** The system learns from reader behavior (which tier they select, how they engage with stories, satisfaction signals) and automatically tunes their `discovery_tolerance` to make better recommendations over time.

---

## Changes Implemented

### Part A: Completion Interview Context Endpoint ‚úÖ

**Location:** `src/routes/feedback.js`

**New Endpoint:** `GET /feedback/completion-context/:storyId`

Fetches rich context for book completion interviews so Prospero has reference points, not just story title.

**Returns:**
```json
{
  "story": {
    "title": "Story Title",
    "genre": "Fantasy",
    "premiseTier": "wildcard"
  },
  "bible": {
    "protagonistName": "Hero Name",
    "supportingCast": ["Character 1", "Character 2"],
    "centralConflict": "Brief description",
    "themes": ["theme1", "theme2"],
    "keyLocations": ["location1", "location2"]
  },
  "readingBehavior": {
    "totalReadingMinutes": 120,
    "lingeredChapters": [
      { "chapter": 7, "minutes": 15 },
      { "chapter": 9, "minutes": 12 }
    ],
    "skimmedChapters": [2, 3],
    "rereadChapters": [
      { "chapter": 7, "sessions": 3 }
    ]
  },
  "checkpointFeedback": [
    { "checkpoint": "chapter_3", "response": "Great", "action": null },
    { "checkpoint": "chapter_6", "response": "Fantastic", "action": null }
  ]
}
```

**Data Sources:**
- `stories` table: title, genre, premise_tier
- `story_bibles` table: characters, central_conflict, themes, key_locations
- `chapter_reading_stats` table: reading time, session counts
- `story_feedback` table: checkpoint responses (Ch 3, 6, 9)

**Authentication:** Scoped to authenticated user via `authenticateUser` middleware

---

### Part B: iOS - Fetch Completion Context and Pass to Prospero ‚úÖ

**Updated Files:**
1. `VoiceSessionManager.swift` - Expanded `BookCompletionContext` struct
2. `APIManager.swift` - Added `getCompletionContext(storyId:)` method
3. `BookCompletionInterviewView.swift` - Updated to fetch and pass rich context

**New BookCompletionContext struct:**
```swift
struct BookCompletionContext {
    let userName: String
    let storyTitle: String
    let storyGenre: String?
    let premiseTier: String?
    let protagonistName: String?
    let centralConflict: String?
    let themes: [String]
    let lingeredChapters: [(chapter: Int, minutes: Int)]
    let skimmedChapters: [Int]
    let rereadChapters: [(chapter: Int, sessions: Int)]
    let checkpointFeedback: [(checkpoint: String, response: String)]
    let bookNumber: Int
}
```

**Enhanced System Prompt:**

Now includes reading behavior observations that Prospero can reference naturally:

```
READING BEHAVIOR:
- They lingered longest on: Ch7 (15m), Ch9 (12m)
- They skimmed: Ch2, Ch3
- They re-read: Ch7 (3x)
- Checkpoint reactions: chapter_3: Great, chapter_6: Fantastic

Use this data naturally in conversation ‚Äî reference specific moments when the reader
clearly engaged deeply. Do NOT recite the data mechanically. Weave it into natural
observations like "I noticed you spent a long time in chapter 7 ‚Äî that scene with
[protagonist] clearly struck a chord."
```

**APIManager Method:**
```swift
func getCompletionContext(storyId: String) async throws -> [String: Any]?
```

Returns nested dictionary with all context data. Handles API errors gracefully with fallback to minimal context.

**BookCompletionInterviewView Update:**

`configureBookCompletionSession()` now:
1. Fetches rich context from API
2. Parses nested response data
3. Builds full `BookCompletionContext` with reading behavior
4. Falls back to minimal context if API fails

---

### Part C: Discovery Tolerance Adjustment Logic ‚úÖ

**Location:** `src/services/generation.js`

**New Function:** `updateDiscoveryTolerance(userId)`

This is the learning loop. Adjusts `discovery_tolerance` based on real behavior over time.

**Adjustment Rules:**

```javascript
// Rule 1: Recent selection patterns
const recentTiers = stories.slice(0, 5).map(s => s.premise_tier);

// Consistently picking comfort across 3+ stories ‚Üí tolerance down
if (comfortCount >= 3) {
  tolerance -= 0.05;
}

// Picking stretch or wildcard ‚Üí tolerance up per pick
tolerance += (stretchCount + wildcardCount) * 0.03;

// Rule 2: Completion feedback on wildcards/stretches
// Positive feedback (loved_it, wanting_more, fantastic) ‚Üí +0.05
// Negative feedback (disappointed, not_for_me) ‚Üí -0.05

// Rule 3: Abandoned wildcards (< 6 chapters read) ‚Üí -0.08

// Clamp to 0.1 - 0.95 range
tolerance = Math.max(0.1, Math.min(0.95, tolerance));
```

**Returns:**
```javascript
{
  tolerance: 0.55,
  changed: true,
  previous: 0.50,
  reason: "Analyzed 5 stories (2C/1S/2W)"
}
```

**When It Runs:**
- After user selects a premise (tracks immediate choice pattern)
- After book completion interview (incorporates satisfaction signal)

---

### Part D: Wire Learning Loop Triggers ‚úÖ

**Trigger 1: After Premise Selection**

**Location:** `src/routes/story.js`, line ~110

```javascript
// Step 2.5: Update discovery tolerance based on selection (non-blocking)
const { updateDiscoveryTolerance } = require('../services/generation');
updateDiscoveryTolerance(userId).catch(err =>
  console.error('Discovery tolerance update failed (non-blocking):', err.message)
);
```

Fires immediately after story record is created, before returning to client. Non-blocking.

**Trigger 2: After Completion Interview**

**Location:** `src/routes/feedback.js`, line ~210

```javascript
// Non-blocking: trigger preference analysis and discovery tolerance update
const { analyzeUserPreferences, updateDiscoveryTolerance } = require('../services/generation');
(async () => {
  try {
    const result = await analyzeUserPreferences(userId);
    console.log(`üìä Preference analysis: ${result.ready ? 'Updated' : result.reason}`);
  } catch (err) {
    console.error('Preference analysis failed (non-blocking):', err.message);
  }
})();

updateDiscoveryTolerance(userId).catch(err =>
  console.error('Discovery tolerance update failed (non-blocking):', err.message)
);
```

Fires after completion interview is stored. Runs alongside `analyzeUserPreferences()`. Both non-blocking.

---

### Part E: Enhanced analyzeUserPreferences() ‚úÖ

**Location:** `src/services/generation.js`, function `analyzeUserPreferences()`

**Changes:**

1. **Fetch premise_tier with stories:**
```javascript
const { data: stories } = await supabaseAdmin
  .from('stories')
  .select('id, title, premise_tier')
  .eq('user_id', userId);
```

2. **Build premise tier history:**
```javascript
const premiseTierHistory = stories
  .map(s => `"${s.title}" ‚Äî tier: ${s.premise_tier || 'unknown'}`)
  .join('\n');
```

3. **Add to analysis prompt:**
```
<premise_tier_history>
"Story Title 1" ‚Äî tier: comfort
"Story Title 2" ‚Äî tier: wildcard
"Story Title 3" ‚Äî tier: stretch
</premise_tier_history>

DISCOVERY PATTERN: Based on premise_tier_history, does this reader tend toward
comfort picks or do they embrace wildcards? Are they happier (better feedback,
more engagement) with familiar or unfamiliar stories? Summarize in one sentence.
```

4. **Updated JSON schema:**
```javascript
{
  // ... existing fields
  "discovery_pattern": "one sentence about comfort vs wildcard preference",
  // ...
}
```

5. **Store in database:**
```javascript
await supabaseAdmin
  .from('user_writing_preferences')
  .upsert({
    // ... existing fields
    discovery_pattern: parsed.discovery_pattern,
    // ...
  })
```

---

### Part F: Database Migration ‚úÖ

**Migration:** `007_add_discovery_pattern.sql`

```sql
ALTER TABLE user_writing_preferences
ADD COLUMN IF NOT EXISTS discovery_pattern TEXT;

COMMENT ON COLUMN user_writing_preferences.discovery_pattern IS
'Pattern analysis: Does this reader prefer comfort (familiar) stories or wildcards (surprises)?
Based on premise_tier selection history and feedback.';
```

**Purpose:** Stores Claude's analysis of whether reader prefers comfort vs wildcard stories.

---

## Testing

**Test Script:** `test-feedback-learning-loop.js`

**Tests:**
1. **Completion context endpoint** - Verifies data fetching from all tables
2. **updateDiscoveryTolerance()** - Runs function with real user data
3. **Code path verification** - Confirms triggers are in place

**Run with:**
```bash
SUPABASE_URL=<url> \
SUPABASE_SERVICE_KEY=<key> \
node test-feedback-learning-loop.js
```

**Expected Output:**
```
üìä TEST 1: Completion Context Endpoint
‚úÖ Story found: Respawn: Normandy
‚úÖ Bible found: Protagonist, themes, conflict
‚úÖ Reading analytics found: X minutes, lingered chapters, etc.
‚úÖ Checkpoint feedback found

üéØ TEST 2: updateDiscoveryTolerance() Function
Current discovery tolerance: 0.5
‚úÖ Function completed: tolerance=0.5, changed=false, reason="No tier-tracked stories yet"

üîç TEST 3: Code Path Verification
‚úÖ TRIGGER 1: Premise Selection
‚úÖ TRIGGER 2: Completion Interview
‚úÖ NEW ENDPOINT: Completion Context
‚úÖ iOS INTEGRATION: All components updated
‚úÖ ENHANCED ANALYSIS: premise_tier_history included

üéâ All tests passed! Learning loop is ready.
```

---

## Analytics Potential

With discovery tolerance tracking, we can analyze:

1. **Tolerance evolution over time:**
   - Do readers start conservative and become more adventurous?
   - What triggers big tolerance shifts?

2. **Tier selection vs tolerance:**
   - Does high tolerance predict wildcard selection?
   - Do readers with low tolerance who pick wildcards have different outcomes?

3. **Satisfaction correlation:**
   - Are readers happier when tolerance matches their actual selections?
   - Do wildcards work better for high-tolerance readers?

4. **Abandonment patterns:**
   - What tolerance level leads to abandoned wildcards?
   - Can we prevent bad wildcard matches by capping tolerance?

5. **Long-term calibration:**
   - Does automatic adjustment improve completion rates?
   - How many stories does it take for tolerance to stabilize?

---

## How It Works (End-to-End)

### 1. User Selects Premise (e.g., Wildcard)
```
User taps "The Quiet Astronaut" (wildcard tier)
  ‚Üí POST /story/select-premise
  ‚Üí Story created with premise_tier='wildcard'
  ‚Üí updateDiscoveryTolerance() fires (non-blocking)
  ‚Üí Checks recent selections: 1 wildcard in last 5
  ‚Üí tolerance += 0.03 (from 0.50 to 0.53)
  ‚Üí Future premises will have slightly bolder wildcards
```

### 2. User Reads Story
```
Reading behavior tracked:
  ‚Üí Ch 1-3: Skimmed (under 2 min each)
  ‚Üí Ch 4-6: Normal pace
  ‚Üí Ch 7: Lingered (15 minutes) + Re-read (3x)
  ‚Üí Ch 8-12: Normal pace, completed
```

### 3. Book Completion Interview
```
GET /feedback/completion-context/:storyId
  ‚Üí Returns: story, bible, reading behavior, checkpoint feedback

Prospero says naturally:
"I noticed you spent a long time in chapter 7 ‚Äî that scene with
the non-verbal astronaut clearly struck a chord. Tell me, what
was it about that moment that seized your heart?"

User shares: "loved_it" satisfaction signal
  ‚Üí POST /feedback/completion-interview
  ‚Üí updateDiscoveryTolerance() fires again
  ‚Üí Sees: wildcard story + "loved_it" feedback
  ‚Üí tolerance += 0.05 (from 0.53 to 0.58)

  ‚Üí analyzeUserPreferences() also fires
  ‚Üí Includes premise_tier_history in prompt
  ‚Üí Stores discovery_pattern: "Gravitates toward wildcards when
     emotional stakes are clear; high comfort with genre departures"
```

### 4. Next Premise Generation
```
User requests new story
  ‚Üí generatePremises() fetches discovery_tolerance = 0.58
  ‚Üí Wildcard calibration: MEDIUM tolerance
  ‚Üí Wildcard premise is bolder than before:
     "A heist story... but in a haunted library. Because you
     loved emotional depth in unexpected settings."
```

### 5. Over Time
```
After 10 stories:
  - 3 comfort picks (tolerance -0.05 * 1 = -0.05)
  - 4 stretch picks (tolerance +0.03 * 4 = +0.12)
  - 3 wildcard picks (tolerance +0.03 * 3 = +0.09)
  - 2 wildcard "loved_it" (tolerance +0.05 * 2 = +0.10)

Net change: +0.26 ‚Üí new tolerance = 0.76 (bold adventurer)

Next wildcard: Genuine genre departure, high risk/reward
```

---

## Edge Cases Handled

1. **No tier-tracked stories yet:**
   - Function returns `changed: false, reason: "No tier-tracked stories yet"`
   - Tolerance stays at default (0.5)

2. **Missing completion interviews:**
   - Rule 2 (satisfaction feedback) skips stories without interviews
   - Rules 1 and 3 still apply

3. **API failure in iOS:**
   - `getCompletionContext()` returns nil
   - Falls back to minimal context (userName, storyTitle, bookNumber)
   - Interview still works, just without reading behavior observations

4. **Tolerance clamping:**
   - Always clamped to 0.1 - 0.95 range
   - Prevents extreme values that could break premise generation

5. **Non-blocking execution:**
   - Both triggers are non-blocking `.catch()` calls
   - If updateDiscoveryTolerance() fails, it doesn't break premise selection or completion interview
   - Errors logged to console but don't propagate to user

---

## Future Enhancements

1. **Explicit tolerance control:**
   - Let readers see their tolerance level in settings
   - Option to manually adjust: "Give me safer picks" / "Surprise me more"

2. **Tolerance decay:**
   - If reader hasn't selected a wildcard in 10 stories, gradually decrease tolerance
   - "Warm them up" before hitting them with bold wildcards again

3. **Tier-specific feedback:**
   - Ask different completion interview questions for wildcards
   - "Was this TOO far from your usual taste, or just right?"

4. **Premise regeneration with tolerance:**
   - "These are too safe, give me 3 wildcards"
   - Temporarily boost tolerance for that generation only

5. **Contextual tolerance:**
   - Different tolerance for different genres
   - Reader might be adventurous in fantasy, conservative in sci-fi

6. **Social comparison:**
   - "Readers like you (tolerance ~0.7) loved these wildcards"
   - Collaborative filtering based on tolerance bands

---

## Implementation Notes

- **No breaking changes:** Existing stories without `premise_tier` are skipped by tolerance calculation
- **Backwards compatible:** Old completion interviews without `satisfactionSignal` are skipped
- **Graceful degradation:** iOS falls back to minimal context if API fails
- **Performance:** All tolerance updates are non-blocking and fire-and-forget
- **Cost:** No additional API calls during premise generation (tolerance already fetched)

---

## Summary

This completes the three-tier discovery engine feedback loop:

**Before:**
- Premises generated once based on initial interview
- No learning from actual behavior
- discovery_tolerance was static

**After:**
- Premises continuously calibrated by real selection patterns
- Completion interviews include reading behavior observations
- discovery_tolerance adjusts automatically based on engagement
- System learns: comfort seeker vs bold explorer
- Future premises get smarter with each story

**The loop is closed:** Behavior ‚Üí Analysis ‚Üí Adjustment ‚Üí Better Recommendations ‚Üí Repeat

---

## Testing Checklist

- [x] Completion context endpoint returns valid data for test story
- [x] updateDiscoveryTolerance() runs without error
- [x] Triggers confirmed in both code locations (story.js, feedback.js)
- [x] iOS successfully fetches and passes rich context
- [x] VoiceSessionManager includes reading behavior in prompt
- [x] analyzeUserPreferences() includes premise_tier_history
- [x] discovery_pattern stored in user_writing_preferences
- [x] Migration 007 adds discovery_pattern column
- [ ] End-to-end test: Select premise ‚Üí Read story ‚Üí Complete interview ‚Üí Check tolerance change
- [ ] Verify Prospero naturally references reading behavior in completion interview

---

**Implementation Complete:** 2026-02-13
**Testing Status:** Backend verified, iOS ready for live testing
